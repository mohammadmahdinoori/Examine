{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS50_Examine_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVYRaWoWJay5"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSHL94ZN8p90",
        "outputId": "29a44d90-05dc-4042-ed8f-78f364639a3f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6by16wABI1Hr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7846b845-072e-4f34-8535-c9c02a7b1341"
      },
      "source": [
        "!sudo apt-get install tesseract-ocr-eng  #for english\n",
        "!sudo apt-get install tesseract-ocr-fas  #for farsi"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr-eng is already the newest version (4.00~git24-0e00fe6-1.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr-fas is already the newest version (4.00~git24-0e00fe6-1.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnqyEUiRI1nJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a0683ab-8d88-47dd-daaa-c888bba60c74"
      },
      "source": [
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.7/dist-packages (0.3.9)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (21.3)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (9.0.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->pytesseract) (3.0.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XWJgpAMckAe"
      },
      "source": [
        "!pip install -q tensorflow_addons"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q Pillow==9.0.0"
      ],
      "metadata": {
        "id": "ZTtjtmD8Vopf"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ctURg1kwWuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4315f1a-60d2-488a-8bf0-97708b99c08e"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x69k-dxUkpip"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "from tensorboard.plugins import projector\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "\n",
        "import pytesseract\n",
        "import cv2 "
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLUHjoHy9SOe"
      },
      "source": [
        "from shutil import copyfile\n",
        "\n",
        "def copyFile(source , destination):\n",
        "  open(destination , mode=\"wb\")\n",
        "  copyfile(source , destination)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cx1bwqy9qad"
      },
      "source": [
        "def saveCheckpoint(path , model , optimizer):\n",
        "  checkpoint = tf.train.Checkpoint(model=model , optimizer=optimizer)\n",
        "  checkpoint.save(path)  "
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lQXD6uaRvPg"
      },
      "source": [
        "def restoreCheckpoint(path , model , optimizer):\n",
        "  checkpoint = tf.train.Checkpoint(model=model , optimizer=optimizer)\n",
        "  checkpoint.restore(tf.train.latest_checkpoint(path))"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09JTw1fGmk2i",
        "outputId": "cb4afc45-4497-478f-b583-ead58cdc92da"
      },
      "source": [
        "strategy = None\n",
        "\n",
        "try:\n",
        "  resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
        "  tf.config.experimental_connect_to_cluster(resolver)\n",
        "  # This is the TPU initialization code that has to be at the beginning.\n",
        "  tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "  print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
        "\n",
        "  strategy = tf.distribute.TPUStrategy(resolver)\n",
        "except:\n",
        "  strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O77fm2N0i47h"
      },
      "source": [
        "#Visualizing in Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km8bqfAgi7wP"
      },
      "source": [
        "def saveEmbeddings(log_dir , model):\n",
        "  def tokenize_items(items):\n",
        "    sequences = tokenizer.texts_to_sequences(items)\n",
        "    sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences , padding=\"post\")\n",
        "    return sequences\n",
        "  \n",
        "  encodings = {}\n",
        "\n",
        "  for category in allQuestions:\n",
        "    for question in allQuestions[category]:\n",
        "      if question.strip() != \"\":\n",
        "        encodings[question] = model(tokenize_items([question]))\n",
        "  \n",
        "  if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "\n",
        "  with open(os.path.join(log_dir, 'metadata.tsv'), \"w\") as f:\n",
        "    for sentence in encodings.keys():\n",
        "      f.write(\"{}\\n\".format(sentence))\n",
        "  \n",
        "  weights = np.array(list(encodings.values()))\n",
        "\n",
        "  weights = tf.Variable(weights[: , 0 , :])\n",
        "\n",
        "  checkpoint = tf.train.Checkpoint(embedding=weights)\n",
        "  checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
        "\n",
        "  # # Set up config.\n",
        "  config = projector.ProjectorConfig()\n",
        "  embedding = config.embeddings.add()\n",
        "\n",
        "  # The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
        "  embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
        "  embedding.metadata_path = 'metadata.tsv'\n",
        "  projector.visualize_embeddings(log_dir, config)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM2nncyYIxfM"
      },
      "source": [
        "#OCR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-N95-amIy7V"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# get grayscale image\n",
        "def get_grayscale(image):\n",
        "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# noise removal\n",
        "def remove_noise(image):\n",
        "    return cv2.medianBlur(image,5)\n",
        " \n",
        "#thresholding\n",
        "def thresholding(image):\n",
        "    return cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "#dilation\n",
        "def dilate(image):\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    return cv2.dilate(image, kernel, iterations = 1)\n",
        "    \n",
        "#erosion\n",
        "def erode(image):\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    return cv2.erode(image, kernel, iterations = 1)\n",
        "\n",
        "#opening - erosion followed by dilation\n",
        "def opening(image):\n",
        "    kernel = np.ones((5,5),np.uint8)\n",
        "    return cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "#canny edge detection\n",
        "def canny(image):\n",
        "    return cv2.Canny(image, 100, 200)\n",
        "\n",
        "#skew correction\n",
        "def deskew(image):\n",
        "    coords = np.column_stack(np.where(image > 0))\n",
        "    angle = cv2.minAreaRect(coords)[-1]\n",
        "    if angle < -45:\n",
        "        angle = -(90 + angle)\n",
        "    else:\n",
        "        angle = -angle\n",
        "    (h, w) = image.shape[:2]\n",
        "    center = (w // 2, h // 2)\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
        "    return rotated\n",
        "\n",
        "#template matching\n",
        "def match_template(image, template):\n",
        "    return cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED) "
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4-OeXaVJGu9"
      },
      "source": [
        "def convert_image_to_text(path=None , image=None , showImage=False):\n",
        "  if path != None:\n",
        "    image = cv2.imread(path)\n",
        "  \n",
        "  image = get_grayscale(image)\n",
        "  image = np.array(thresholding(image))\n",
        "\n",
        "  if showImage:\n",
        "    plt.imshow(image)\n",
        "\n",
        "  config = r'-l fas+eng --psm 6'\n",
        "\n",
        "  return pytesseract.image_to_string(image , config=config)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qZJB93W6mlu"
      },
      "source": [
        "#LASM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co7TV3Ih6nnp"
      },
      "source": [
        "class LinearAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self , d_model , heads , dropout=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    assert d_model % heads == 0\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.heads = heads\n",
        "\n",
        "    self.wq = tf.keras.layers.Dense(d_model)\n",
        "    self.wk = tf.keras.layers.Dense(d_model)\n",
        "    self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.wo = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "    self.norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "  def split_heads(self , items):\n",
        "    items = tf.reshape(items , shape=(tf.shape(items)[0] , -1 , self.heads , self.d_model//self.heads))\n",
        "    return tf.experimental.numpy.swapaxes(items , -3 , -2)\n",
        "\n",
        "  def call(self , query , key , value , mask=None , training=True):\n",
        "\n",
        "    normedQ = self.norm(query)\n",
        "    \n",
        "    q = self.split_heads(self.wq(normedQ))\n",
        "    k = self.wk(key)\n",
        "    v = self.wv(value)\n",
        "\n",
        "    if mask != None:\n",
        "      k *= mask\n",
        "      v *= mask\n",
        "    \n",
        "    k = self.split_heads(k)\n",
        "    v = self.split_heads(v)\n",
        "\n",
        "    transformedQ = tf.nn.elu(q) + 1\n",
        "    transformedK = tf.nn.elu(k) + 1\n",
        "\n",
        "    keysSum = tf.reduce_sum(transformedK , axis=-2 , keepdims=True)\n",
        "\n",
        "    attentionResult = tf.matmul(transformedQ , tf.matmul(transformedK , v , transpose_a=True)) / tf.matmul(transformedQ , keysSum , transpose_b=True)\n",
        "\n",
        "    attentionResult = tf.reshape(tf.experimental.numpy.swapaxes(attentionResult , -3 , -2) , shape=(tf.shape(attentionResult)[0] , -1 , self.d_model))\n",
        "\n",
        "    result = self.wo(attentionResult)\n",
        "    \n",
        "    result = self.dropout(result , training=training)\n",
        "\n",
        "    return query + result"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ91-pvo6qWT"
      },
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "  def __init__(self , d_model , rate=2 , dropout=0.1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.model = tf.keras.Sequential([\n",
        "                                      tf.keras.layers.LayerNormalization(epsilon=1e-6),\n",
        "                                      tf.keras.layers.Dense(d_model * rate , activation=\"gelu\"),\n",
        "                                      tf.keras.layers.Dropout(dropout),\n",
        "                                      tf.keras.layers.Dense(d_model , activation=\"gelu\"),\n",
        "                                      tf.keras.layers.Dropout(dropout),\n",
        "    ])\n",
        "  \n",
        "  def call(self , inputs , training=True):\n",
        "    x = self.model(inputs)\n",
        "    return inputs + x"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J5RiKYo6sJH"
      },
      "source": [
        "class TransformerEncoder(tf.keras.Model):\n",
        "  def __init__(self , d_model , heads , ffnRate=2 , layers=1 , dropout=0.1):\n",
        "    super().__init__()\n",
        "    self.encoders = [(LinearAttention(d_model , heads , dropout) , FeedForward(d_model , ffnRate , dropout)) for _ in range(layers)]\n",
        "\n",
        "  def call(self , inputs , mask=None , training=True):\n",
        "    x = inputs\n",
        "\n",
        "    for (att , ffn) in self.encoders:\n",
        "      x = att(x , x , x , mask , training)\n",
        "      x = ffn(x , training)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWM9gY856u0h"
      },
      "source": [
        "class LASM(tf.keras.Model):\n",
        "  def __init__(self , units , d_model , heads , ffnRate=2 , layers=1 , maxPositions=10000 , dropout=0.1 , usePositionalEncoding=False):\n",
        "    super().__init__()\n",
        "\n",
        "    assert d_model // heads\n",
        "\n",
        "    self.num_of_units = units\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.heads = heads\n",
        "\n",
        "    self.maxPositions = maxPositions\n",
        "\n",
        "    self.encoder = TransformerEncoder(d_model , heads , ffnRate , layers , dropout)\n",
        "\n",
        "    self.units = tf.Variable(tf.keras.initializers.GlorotNormal()(shape=(1 , units , d_model)))\n",
        "  \n",
        "    self.usePositionalEncoding = usePositionalEncoding\n",
        "\n",
        "  def positionalEncoding(self):\n",
        "    i = np.arange(self.d_model)//2\n",
        "\n",
        "    encodings = (np.arange(self.maxPositions)[... , np.newaxis]) *  (1 / (np.power(10000 , (2 * i) / self.d_model)))[np.newaxis , ...]\n",
        "\n",
        "    encodings[: , 0::2] = np.sin(encodings[: , 0::2])\n",
        "    encodings[: , 1::2] = np.cos(encodings[: , 1::2])\n",
        "\n",
        "    return encodings[np.newaxis , ...]\n",
        "  \n",
        "  def call(self , inputs , mask=None , training=True):\n",
        "    if self.usePositionalEncoding:\n",
        "      sequenceLength = tf.shape(inputs)[1]\n",
        "\n",
        "      if sequenceLength != None:\n",
        "        inputs += self.positionalEncoding()[: , :sequenceLength , :]\n",
        "\n",
        "    units  = tf.repeat(self.units , tf.shape(inputs)[0] , axis=0)\n",
        "\n",
        "    if mask != None:\n",
        "      mask = tf.concat((tf.ones(shape=(tf.shape(inputs)[0] , self.num_of_units , 1)) , mask) , axis=1)\n",
        "\n",
        "    inputs = tf.concat((units , inputs) , axis=1)\n",
        "\n",
        "    encoderResult = self.encoder(inputs , mask , training)\n",
        "    \n",
        "    summerizersResult = encoderResult[: , :self.num_of_units , :]\n",
        "\n",
        "    summerizersResult = tf.reduce_mean(summerizersResult , axis=1) \n",
        "\n",
        "    return summerizersResult"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx7xY6rS6hpg"
      },
      "source": [
        "#Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd5Pcw7zkqi4"
      },
      "source": [
        "lines = None\n",
        "with open(\"/content/gdrive/MyDrive/Examine - CS50x Fair/Dataset.txt\" , \"r\") as f:\n",
        "  lines = f.readlines()"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWRjBvJQksGq"
      },
      "source": [
        "text = ''.join(lines)\n",
        "\n",
        "sections = text.split(\"<Section End>\")\n",
        "\n",
        "allQuestions = {}\n",
        "\n",
        "listOfQuestions = []\n",
        "\n",
        "for item in sections:\n",
        "  header , items = item.split(\"<Head End>\")\n",
        "  questions = [question.replace(\"\\n\" , \"\").strip() for question in items.split(\"<end>\")]\n",
        "  allQuestions[header.replace(\"\\n\" , \"\").strip()] = questions\n",
        "  for _item in questions:\n",
        "    listOfQuestions.append(_item)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgB3yLilkteB"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=\"<UNK>\" , filters='')\n",
        "tokenizer.fit_on_texts(listOfQuestions)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bneLwrijkvbb"
      },
      "source": [
        "def tokenize(items):\n",
        "  return tokenizer.texts_to_sequences(items)\n",
        "\n",
        "def de_tokenize(items):\n",
        "  return tokenizer.sequences_to_texts(items)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieMGCiJ_kwis"
      },
      "source": [
        "maxLen = max([len(item) for item in tokenize(listOfQuestions)])"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions_1 = []\n",
        "questions_2 = []\n",
        "labels = []\n",
        "\n",
        "negativeCounter = 0\n",
        "negativePossibility = 6230*[1] + (6230-6230)*[0]\n",
        "random.shuffle(negativePossibility)\n",
        "\n",
        "for key_1, value_1 in allQuestions.items():\n",
        "  for question_1 in value_1:\n",
        "    for key_2, value_2 in allQuestions.items():\n",
        "      for question_2 in value_2:\n",
        "        if question_1 != question_2:\n",
        "          if key_1 == key_2:\n",
        "            questions_1.append(tokenize([question_1])[0])\n",
        "            questions_2.append(tokenize([question_2])[0])\n",
        "            labels.append(1)\n",
        "          else:\n",
        "            if negativePossibility[negativeCounter] == 1:\n",
        "              questions_1.append(tokenize([question_1])[0])\n",
        "              questions_2.append(tokenize([question_2])[0])\n",
        "              labels.append(0)\n",
        "          \n",
        "            negativeCounter += 1"
      ],
      "metadata": {
        "id": "DZ0S7KS4vBEJ"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions_1 = tf.keras.preprocessing.sequence.pad_sequences(questions_1 , maxlen=maxLen , padding='post')\n",
        "questions_2 = tf.keras.preprocessing.sequence.pad_sequences(questions_2 , maxlen=maxLen , padding='post')"
      ],
      "metadata": {
        "id": "8YcSf8f1wGWR"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions_1 = np.array(questions_1)[:, np.newaxis, :]\n",
        "questions_2 = np.array(questions_2)[:, np.newaxis, :]\n",
        "labels = np.array(labels)[:, np.newaxis]\n",
        "\n",
        "questions = np.concatenate((questions_1 , questions_2) , axis=1)"
      ],
      "metadata": {
        "id": "6i3vbEHVwViV"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(questions_1.shape)\n",
        "print(questions_2.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "print(questions.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Xi0v0MNwebm",
        "outputId": "0f7d37d1-b6c4-4a52-9f8c-7f4f992fe188"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7826, 1, 71)\n",
            "(7826, 1, 71)\n",
            "(7826, 1)\n",
            "(7826, 2, 71)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QP1zBQyvlDk5"
      },
      "source": [
        "trainingData = tf.data.Dataset.from_tensor_slices((questions , labels)).shuffle(len(labels)).batch(256 , drop_remainder=True)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainingData"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsgTw_qQxHlO",
        "outputId": "86e1b3b9-ee05-4618-d55d-99d6ca15da37"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 2, 71), dtype=tf.int32, name=None), TensorSpec(shape=(256, 1), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl2Kvty86dw9"
      },
      "source": [
        "#Defining Model and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFHOMxzqlFHB"
      },
      "source": [
        "class ExtractorModel(tf.keras.Model):\n",
        "  def __init__(self , vocab_size):\n",
        "    super().__init__()\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size , 256 , mask_zero=True)\n",
        "\n",
        "    self.encoder = LASM(1 , 256 , 4 , 2 , 2)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(256 , activation='gelu')\n",
        "  \n",
        "  def make_mask(self , items):\n",
        "    mask = tf.cast(tf.logical_not(tf.equal(items , 0)) , tf.float32)[... , tf.newaxis]\n",
        "    return mask\n",
        "\n",
        "  def call(self , inputs , training=True):\n",
        "    mask = self.make_mask(inputs)\n",
        "\n",
        "    x = self.embedding(inputs)\n",
        "    x = self.encoder(x , mask , training)\n",
        "    result = self.dense(x)\n",
        "\n",
        "    return result"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg8Rol2glIGF"
      },
      "source": [
        "class MatcherModel(tf.keras.Model):\n",
        "  def __init__(self , exctractor , similarityFunction):\n",
        "    super().__init__()\n",
        "    self.extractor = exctractor\n",
        "    self.similarityLayer = tf.keras.layers.Lambda(similarityFunction)\n",
        "\n",
        "  def call(self , inputs , training=True):\n",
        "    firstX = inputs[: , 0  , :]\n",
        "    secondX = inputs[: , 1 , :]\n",
        "\n",
        "    result_1 = self.extractor(firstX , training=training)\n",
        "    result_2 = self.extractor(secondX , training=training)\n",
        "\n",
        "    result = self.similarityLayer([result_1 , result_2])\n",
        "\n",
        "    return result"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8sjwnUmlJ4V"
      },
      "source": [
        "import sys\n",
        "\n",
        "def distance_function(items):\n",
        "  first = items[0]\n",
        "  second = items[1]\n",
        "\n",
        "  distance = tf.reduce_sum(tf.square(first - second) , axis=1 , keepdims=True)\n",
        "\n",
        "  return distance"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUOfe5LF3dEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e487070-809a-44a9-fdc3-c53e6364b854"
      },
      "source": [
        "with strategy.scope():\n",
        "  lossObject = tfa.losses.ContrastiveLoss(margin=2.0)\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "  metric = tf.keras.metrics.Accuracy()\n",
        "\n",
        "  vocab_size = len(tokenizer.index_word) + 1\n",
        "\n",
        "  extractorModel = ExtractorModel(vocab_size)\n",
        "\n",
        "  model = MatcherModel(extractorModel , distance_function)\n",
        "\n",
        "  model.compile(loss=lossObject , optimizer=optimizer , metrics=[metric])\n",
        "\n",
        "  for item in trainingData.take(1):\n",
        "    model(item[0])"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "_A2jGsPfSjoF"
      },
      "source": [
        "#@title Raw Model Options\n",
        "restore_model = \"Yes\" #@param [\"Yes\", \"No\"]\n",
        "restore_checkpoint_path = \"/content/gdrive/MyDrive/Examine - CS50x Fair/Raw Checkpoints/\" #@param {type:\"string\"}\n",
        "saveCheckpoints = \"No\" #@param [\"Yes\", \"No\"]\n",
        "save_checkpoint_path = \"/content/gdrive/MyDrive/Examine - CS50x Fair/Raw Checkpoints/\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "if restore_model.lower() == \"yes\":\n",
        "  restoreCheckpoint(restore_checkpoint_path , model , optimizer)\n",
        "\n",
        "if saveCheckpoints.lower() == \"yes\":\n",
        "  saveCheckpoint(save_checkpoint_path , model , optimizer)\n",
        "\n",
        "saveEmbeddings(\"/content/gdrive/MyDrive/Examine - CS50x Fair/Embeddings Raw/\" , extractorModel)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "3C4j_9OtVbVp"
      },
      "source": [
        "#@title Training Options\n",
        "train_model = \"No\" #@param [\"Yes\", \"No\"]\n",
        "\n",
        "restore_model = \"Yes\" #@param [\"Yes\", \"No\"]\n",
        "restore_checkpoint_path = \"/content/gdrive/MyDrive/Examine - CS50x Fair/Trained Checkpoints/\" #@param {type:\"string\"}\n",
        "\n",
        "saveCheckpoints = \"No\" #@param [\"Yes\", \"No\"]\n",
        "save_checkpoint_path = \"/content/gdrive/MyDrive/Examine - CS50x Fair/Trained Checkpoints/\" #@param {type:\"string\"}\n",
        "\n",
        "if restore_model.lower() == \"yes\":\n",
        "  restoreCheckpoint(restore_checkpoint_path , model , optimizer)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saveEmbeddings(\"/content/gdrive/MyDrive/Examine - CS50x Fair/Embeddings Trained/\" , extractorModel)"
      ],
      "metadata": {
        "id": "D-62YB71ybQn"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6EvqPj36cMg",
        "outputId": "6548ee60-d1af-4842-8041-de0aea607098"
      },
      "source": [
        "if train_model.lower() == \"yes\":\n",
        "  model.fit(trainingData , epochs=10)\n",
        "\n",
        "if saveCheckpoints.lower() == \"yes\":\n",
        "  saveCheckpoint(save_checkpoint_path , model , optimizer)\n",
        "\n",
        "saveEmbeddings(\"/content/gdrive/MyDrive/Examine - CS50x Fair/Embeddings Trained/\" , extractorModel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 22s 400ms/step - loss: 2.5381 - accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 12s 400ms/step - loss: 0.7101 - accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 12s 400ms/step - loss: 0.5161 - accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 12s 399ms/step - loss: 0.3202 - accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 12s 400ms/step - loss: 0.1361 - accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 12s 400ms/step - loss: 0.0864 - accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 12s 400ms/step - loss: 0.0675 - accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 12s 401ms/step - loss: 0.0553 - accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 12s 400ms/step - loss: 0.0550 - accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 12s 400ms/step - loss: 0.0462 - accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDty6XOxwpda"
      },
      "source": [
        "#Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5UnIwCTlcrX"
      },
      "source": [
        "def get_similar_questions(question , num_of_matches=10):\n",
        "  firstQuestions = []\n",
        "  secondQuestions = []\n",
        "\n",
        "  newMaxLen  = len(tokenize([question])[0])\n",
        "\n",
        "  newMaxLen = max(newMaxLen , maxLen)\n",
        "\n",
        "  question = tf.keras.preprocessing.sequence.pad_sequences(tokenize([question]) , maxlen=newMaxLen , padding='post')[0]\n",
        "\n",
        "  allQuestions = tf.keras.preprocessing.sequence.pad_sequences(tokenize(listOfQuestions) , maxlen=newMaxLen , padding='post')\n",
        "\n",
        "  for item in allQuestions:\n",
        "    firstQuestions.append(question)\n",
        "    secondQuestions.append(item)\n",
        "\n",
        "  firstQuestions = np.expand_dims(firstQuestions , axis=1)\n",
        "  secondQuestions = np.expand_dims(secondQuestions , axis=1)\n",
        "\n",
        "  final_items = np.concatenate((firstQuestions , secondQuestions) , axis=1)\n",
        "\n",
        "  result = np.squeeze(model(final_items) , axis=-1)\n",
        "\n",
        "  matches = np.argpartition(result, num_of_matches)[:num_of_matches]\n",
        "\n",
        "  matchedItems = np.squeeze(secondQuestions[matches , :] , axis=1)\n",
        "\n",
        "  matchedItems = de_tokenize(matchedItems)\n",
        "\n",
        "  final_questions = []\n",
        "\n",
        "  for item in matchedItems:\n",
        "    final_questions.append(str(item).replace(\"<UNK>\" , \"\").strip())\n",
        "  \n",
        "  return final_questions , ''.join([item + \"\\n\" if item.strip() != \"\" else \"\" for item in final_questions])"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id8newgflg7N",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815a4753-240e-4355-be27-a0bad3a47ab2"
      },
      "source": [
        "#@title Question Matcher With Text { vertical-output: true }\n",
        "Question = \"\\u0686\\u0646\\u062F\\u0645\\u064A\\u0646 \\u062C\\u0645\\u0644\\u0647 \\u0627\\u0632 \\u062F\\u0646\\u0628\\u0627\\u0644\\u0647 \\u062D\\u0633\\u0627\\u0628\\u06CC ... \\u0648 8 \\u0648 5 \\u0648 2 \\u0628\\u0631\\u0627\\u0628\\u0631 56 \\u0627\\u0633\\u062A \\u061F\" #@param {type:\"string\"}\n",
        "NumOfMatches =  10#@param {type:\"integer\"}\n",
        "questionsList , result = get_similar_questions(Question , num_of_matches=NumOfMatches)\n",
        "print(result)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "در یک دنباله حسابی مجموع سه جمله اول و سه جمله آخر ۲۴۰ است. اگر مجموع همه جملات دنباله برابر ۵۲۰ باشد، این دنباله چند جمله دارد؟\n",
            "مجموع اعداد طبیعی از ۱ تا ۲۰ کدام است؟‌\n",
            "در بیست جمله اول از یک دنباله حسابی، مجموع جملات ردیف فرد ۱۳۵ و مجموع جملات ردیف زوج ۱۵۰ است. جمله اول کدام است؟\n",
            "مجموع ۱۰ جمله اول یک دنباله حسابی برابر ۲۵ است. به هر یک از جمله ها ۶ واحد اضافه کرده و سپس در ۲ ضرب کرده و در پایان ۳ واحد از هر یک کم می کنیم. مجموع ۱۰ جمله اول دنباله حاصل کدام است ؟‌\n",
            "مجموع اعداد طبیعی فرد، بخش پذیر بر ۳ و کوچک تر از ۱۰۱ کدام است؟\n",
            "در دنباله حسابی ... ۵٫۸٫۱۱٫ حداقل چند جمله باید با هم جمع شوند تا حاصل از ۵۰۰ بیشتر شود؟\n",
            "مجموع همه اعداد طبیعی دورقمی که مضرب ۶ هستند، کدام است؟\n",
            "در یک دنباله حسابی ، جمله هفتم نصف جمله سوم است. مجموع چند جمله اول از این دنباله ،‌ صفر است ‌؟‌\n",
            "در یک دنباله حسابی ،‌ جلمه اول برابر ۵ و هر جمله از جمله ما قبل خود به اندازه ۱/۲ کم تر است. مجموع ده جمله اول آن کدام است؟\n",
            "اگر مجموع چهار جمله اول یک دنباله حسابی ۲ واحد از مجموع سه جمله اول بیشتر و ۵ واحد از مجموع پنج جمله اول کمتر باشد، قدرنسبت دنباله کدام است؟\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkFpPdPMlj6I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "924773b3-f9fd-4ce3-cd19-2ccefb2ee967",
        "cellView": "form"
      },
      "source": [
        "#@title Question Matcher With Image{ vertical-output: true }\n",
        "ImagePath = \"/content/gdrive/MyDrive/Examine - CS50x Fair/Image.png\" #@param {type:\"string\"}\n",
        "NumOfMatches =  10#@param {type:\"integer\"}\n",
        "\n",
        "Question = convert_image_to_text(path=ImagePath , showImage=True)\n",
        "print()\n",
        "\n",
        "questionsList , result = get_similar_questions(Question , num_of_matches=NumOfMatches)\n",
        "print(result)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "تعداد جملات یک دنباله هندسی عددی زوج است. اگر مجموع تمام جملات آن ۳ برابر مجموع جملات با ردیف فرد باشد، قدرنسبت آن کدام است؟\n",
            "در یک دنباله حسابی جمله n ام به صورت an = ۳/۲n-5 است. مجموع ۱۵ جمله اول این دنباله ، کدام است ؟\n",
            "مجموع پنج جمله اول دنباله هندسی ۳۶٫۱۸٫۹٫۰۰۰ کدام است؟\n",
            "اگر در خانه اول شطرنج ۱ گندم، در خانه دوم ۲ گندم، در خانه سوم ۴ گندم و به همین ترتیب در هر خانه دو برابر خانه قبل، گندم قرار دهیم، اولین خانه ای که مجموع تعداد گندمها تا آن خانه بیشتر از ۴۱۰۰ خواهد بود، کدام است؟\n",
            "مجموع چند جمله دنباله هندسی ... ۱۲٫۲۴٫ -۶٫ برابر ۱۰۲۶ است؟\n",
            "در یک دنباله هندسی با قدرنسبت مثبت، مجموع جملات سوم و ششم برابر ۱۴ و تفاضل جملات سوم و نهم برابر ۹۸ است. مجموع چهار جمله اول کدام است؟\n",
            "بین دو عدد ۳۲۴ و ۴، سه عدد چنان درج شده است که پنج عدد حاصل تشکیل یک دنباله هندسی دهند. مجموع این ۵ عدد مثبت کدام است؟\n",
            "در یک دنباله هندسی، مجموع ۸ جمله اول ۴۸ و مجموع جملات شروع از جمله چهارم و ختم به جمله یازدهم برابر ۲۴۰ است. قدرنسبت دنباله کدام است؟\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFZ3dlHFwu7Y"
      },
      "source": [
        "#Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDkyH49ejHrV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "c7234b6e-92f7-4c67-a3ee-e126ca0d1e3f"
      },
      "source": [
        "%tensorboard --logdir /content/gdrive/MyDrive/Examine - CS50x Fair/Embeddings Raw"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 2).\n",
              "Contents of stderr:\n",
              "usage: tensorboard [-h] [--helpfull] [--logdir PATH] [--logdir_spec PATH_SPEC]\n",
              "                   [--host ADDR] [--bind_all] [--port PORT]\n",
              "                   [--reuse_port BOOL] [--load_fast {false,auto,true}]\n",
              "                   [--extra_data_server_flags EXTRA_DATA_SERVER_FLAGS]\n",
              "                   [--grpc_creds_type {local,ssl,ssl_dev}]\n",
              "                   [--grpc_data_provider PORT] [--purge_orphaned_data BOOL]\n",
              "                   [--db URI] [--db_import] [--inspect] [--version_tb]\n",
              "                   [--tag TAG] [--event_file PATH] [--path_prefix PATH]\n",
              "                   [--window_title TEXT] [--max_reload_threads COUNT]\n",
              "                   [--reload_interval SECONDS] [--reload_task TYPE]\n",
              "                   [--reload_multifile BOOL]\n",
              "                   [--reload_multifile_inactive_secs SECONDS]\n",
              "                   [--generic_data TYPE]\n",
              "                   [--samples_per_plugin SAMPLES_PER_PLUGIN]\n",
              "                   [--whatif-use-unsafe-custom-prediction YOUR_CUSTOM_PREDICT_FUNCTION.py]\n",
              "                   [--whatif-data-dir PATH]\n",
              "                   {serve,dev} ...\n",
              "tensorboard: error: invalid choice: '-' (choose from 'serve', 'dev')"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK4-D8zvwJt-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d14d201e-2d63-4fe2-d52c-af455d9b898f"
      },
      "source": [
        "%tensorboard --logdir \"/content/gdrive/MyDrive/Examine - CS50x Fair/Embeddings Trained\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Launching TensorBoard..."
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
